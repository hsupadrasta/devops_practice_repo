# Commented out IPython magic to ensure Python compatibility.
# Generic Libraries
import re
import pandas as pd # For creating dataframes of extracted information
import bs4
import requests
from tqdm import tqdm

# NLP Specific Libraries
import spacy
from spacy import displacy
nlp = spacy.load('en_core_web_sm')
from spacy.matcher import Matcher
from spacy.tokens import Span

# Libraries for displaying Knowledge Graph
import networkx as nx
import matplotlib.pyplot as plt


pd.set_option('display.max_colwidth', 200)
# %matplotlib inline

"""# **Understanding the Dependency Parser**"""

doc = nlp("user creates License and then creates a appointment based on the license information")

for tok in doc:
  print(tok.text, "->", tok.dep_)

doc = nlp("Christiano Ronaldo plays for Juventus")

for tok in doc:
  print(tok.text, "->", tok.dep_)

"""# **A Simple Example**

**Let us take a set of sentences on 'India'**
"""

sentences_India = ['India is known as Bharat',
             'India is a country in South Asia',
             'India is the seventh-largest country',
             'India is a democratic country',
             'India has its President as Ram Nath Kovind',
             'India has Prime Minister as Narendra Modi'
            ]

sentences_India[1]

"""**Convert Sentences to a pandas dataframe**"""

India_df = pd.DataFrame(sentences_India, columns =['India'])

India_df.head(6)

"""# **Information Extraction**
**Extract Entities and Relations**

## **Function to extract *entities* from text**
"""

def get_entities(sent):
  head_entity = ""
  candidate_entity = ""

  prv_tok_dep = ""    # dependency tag of previous token in the sentence
  prv_tok_text = ""   # previous token in the sentence

  prefix = ""

  for tok in nlp(sent):
    # If token is a punctuation mark then move on to the next token
    if tok.dep_ != "punct":

      # CHECK: token is a 'compound' or 'modifier' or 'attribute'
      if tok.dep_ == "compound" or tok.dep_.endswith("mod") or tok.dep_ == "attr":
        prefix = tok.text

        # If the previous word was also a 'compound' or 'modifier' or 'attribute', then add the current word to it
        if prv_tok_dep == "compound" or prv_tok_dep.endswith("mod") or prv_tok_dep == "attr":
          prefix = prv_tok_text + " " + tok.text

      # Assign head entity or, subject
      if tok.dep_.find("subj") == True:
        head_entity = prefix + " " + tok.text
        prefix = ""
        prv_tok_dep = ""
        prv_tok_text = ""

      # Assign candidate entity or, object
      if tok.dep_.find("obj") == True:
        candidate_entity = prefix + " " + tok.text
      else:
        candidate_entity = prefix # In some cases the candidate entity is an 'attribute'

      # Update variables
      prv_tok_dep = tok.dep_
      prv_tok_text = tok.text

  return [head_entity.strip(), candidate_entity.strip()]

get_entities("Christiano Ronaldo scored 3 goals")

"""## **Extract Head Entity and Candidate Entity (Subject and Object) from text**"""

entity_pairs = []

for i in tqdm(India_df["India"]):
  entity_pairs.append(get_entities(i))

entity_pairs[0:6]

"""## **Function to extract *relations* from text**"""

def get_relation(sent):

  doc = nlp(sent)

  # Matcher class object
  matcher = Matcher(nlp.vocab)

  #define the pattern
  pattern = [{'DEP':'ROOT'},
            {'DEP':'prep','OP':"?"},
            {'DEP':'agent','OP':"?"},
            {'POS':'ADJ','OP':"?"}]

  matcher.add("matching_1", [pattern])


  matches = matcher(doc)
  k = len(matches) - 1

  span = doc[matches[k][1]:matches[k][2]]

  return(span.text)

"""## **Extract Relations (Predicates) from text**"""

relations = [get_relation(i) for i in tqdm(India_df['India'])]

relations[0:5]

"""## **Identify *subject/source* from entities**"""

source = [i[0] for i in entity_pairs]

"""## **Identify *object/target* from entities**"""

target = [i[1] for i in entity_pairs]

"""## **Create dataframe in <*subject, object, predicate*> format**
## **This is <*source, target, edge*> in knowledge graph**
"""

kg_df = pd.DataFrame({'source':source, 'target':target, 'edge':relations})
kg_df.head()

"""# **Construct knowledge graph**"""

KG_India = nx.from_pandas_edgelist(kg_df, "source", "target",
                          edge_attr=True, create_using=nx.MultiDiGraph())

"""# **Plot knowledge graph**"""

plt.figure(figsize=(12,12))
pos = nx.spring_layout(KG_India)
nx.draw(KG_India, with_labels=True, node_color='lightgreen', node_size=1500, edge_cmap=plt.cm.Blues, pos = pos)
plt.show()

"""# **Constructing Knowledge Graph on Large *unstructured* text**

## **Import wikipedia sentences**
"""

unstructured_text = pd.read_csv("/content/sample_data/wiki_sentences_v2.csv")
unstructured_text.shape

unstructured_text['sentence'].sample(5)

unstructured_text.head(20)

"""## **Extract Entities from *unstructured* text**"""

entity_pairs = []

for i in tqdm(unstructured_text["sentence"]):
  entity_pairs.append(get_entities(i))

entity_pairs[5:10]

"""## **Extract relations from *unstructured* text**"""

relations = [get_relation(i) for i in tqdm(unstructured_text['sentence'])]

"""## **Create dataframe in <*source, target, edge*> format**"""

source = [i[0] for i in entity_pairs]

target = [i[1] for i in entity_pairs]

kg_df = pd.DataFrame({'source':source, 'target':target, 'edge':relations})
kg_df.head(6)

"""### **Show top *50* relations**"""

pd.Series(relations).value_counts()[:50]

"""## **Construct and Plot Knowledge Graph for *unstructured* text**"""

# Construct knowledge graph over extracted information (dataframe)
KG = nx.from_pandas_edgelist(kg_df, "source", "target",
                          edge_attr=True, create_using=nx.MultiDiGraph())

# Plot Knowledge Graph
plt.figure(figsize=(12,12))
pos = nx.spring_layout(KG)
nx.draw(KG, with_labels=True, node_color='lightgreen', edge_cmap=plt.cm.Blues, pos = pos)
plt.show()

"""## **Construct knowledge graph for a *single* relation**"""

KG_rel = nx.from_pandas_edgelist(kg_df[kg_df['edge']=="composed by"], "source", "target",
                          edge_attr=True, create_using=nx.MultiDiGraph())

plt.figure(figsize=(12,12))
pos = nx.spring_layout(KG_rel, k = 0.5) # k regulates the distance between nodes
nx.draw(KG_rel, with_labels=True, node_color='lightgreen', node_size=1500, edge_cmap=plt.cm.Blues, pos = pos)
plt.show()

